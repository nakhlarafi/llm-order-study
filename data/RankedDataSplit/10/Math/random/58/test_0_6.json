{
    "bug_id": 58,
    "test_id": 0,
    "test_name": "org.apache.commons.math.optimization.fitting.GaussianFitterTest.testMath519",
    "test_body": "public void testMath519() {\n// The optimizer will try negative sigma values but \"GaussianFitter\"\n// will catch the raised exceptions and return NaN values instead.\n302: final double[] data = { \n1.1143831578403364E-29,\n4.95281403484594E-28,\n1.1171347211930288E-26,\n1.7044813962636277E-25,\n1.9784716574832164E-24,\n1.8630236407866774E-23,\n1.4820532905097742E-22,\n1.0241963854632831E-21,\n6.275077366673128E-21,\n3.461808994532493E-20,\n1.7407124684715706E-19,\n8.056687953553974E-19,\n3.460193945992071E-18,\n1.3883326374011525E-17,\n5.233894983671116E-17,\n1.8630791465263745E-16,\n6.288759227922111E-16,\n2.0204433920597856E-15,\n6.198768938576155E-15,\n1.821419346860626E-14,\n5.139176445538471E-14,\n1.3956427429045787E-13,\n3.655705706448139E-13,\n9.253753324779779E-13,\n2.267636001476696E-12,\n5.3880460095836855E-12,\n1.2431632654852931E-11\n};\n332: GaussianFitter fitter = new GaussianFitter(new LevenbergMarquardtOptimizer());\nfor (int i = 0; i < data.length; i++) {\nfitter.addObservedPoint(i, data[i]);\n}\nfinal double[] p = fitter.fit();\n338: Assert.assertEquals(53.1572792, p[1], 1e-7);\nAssert.assertEquals(5.75214622, p[2], 1e-8);\n}\n",
    "stack_trace": "org.apache.commons.math.exception.NotStrictlyPositiveException: -1.277 is smaller than, or equal to, the minimum (0)\nat org.apache.commons.math.analysis.function.Gaussian$Parametric.validateParameters(Gaussian.java:183)\nat org.apache.commons.math.analysis.function.Gaussian$Parametric.value(Gaussian.java:128)\nat org.apache.commons.math.optimization.fitting.CurveFitter$TheoreticalValuesFunction.value(CurveFitter.java:203)\nat org.apache.commons.math.optimization.direct.BaseAbstractVectorialOptimizer.computeObjectiveValue(BaseAbstractVectorialOptimizer.java:107)\nat org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer.updateResidualsAndCost(AbstractLeastSquaresOptimizer.java:128)\nat org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer.doOptimize(LevenbergMarquardtOptimizer.java:350)\nat org.apache.commons.math.optimization.direct.BaseAbstractVectorialOptimizer.optimize(BaseAbstractVectorialOptimizer.java:141)\nat org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer.optimize(AbstractLeastSquaresOptimizer.java:253)\nat org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer.optimize(AbstractLeastSquaresOptimizer.java:43)\nat org.apache.commons.math.optimization.fitting.CurveFitter.fit(CurveFitter.java:160)\nat org.apache.commons.math.optimization.fitting.CurveFitter.fit(CurveFitter.java:126)\nat org.apache.commons.math.optimization.fitting.GaussianFitter.fit(GaussianFitter.java:121)\nat org.apache.commons.math.optimization.fitting.GaussianFitterTest.testMath519(GaussianFitterTest.java:336)",
    "covered_methods": [
        {
            "method_signature": "org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer:updateJacobian()V",
            "method_body": "protected void updateJacobian() {\n++jacobianEvaluations;\nweightedResidualJacobian = jF.value(point);\nif (weightedResidualJacobian.length != rows) {\nfinal double[] residualsWeights = getWeightRef();\nfor (int i = 0; i < rows; i++) {\nfinal double[] ji = weightedResidualJacobian[i];\ndouble wi = FastMath.sqrt(residualsWeights[i]);\nfor (int j = 0; j < cols; ++j) {\nweightedResidualJacobian[i][j] = -ji[j]*wi;\n}",
            "method_id": 60
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.GaussianFitter$ParameterGuesser$1:compare(Lorg/apache/commons/math/optimization/fitting/WeightedObservedPoint;Lorg/apache/commons/math/optimization/fitting/WeightedObservedPoint;)I",
            "method_body": "private Comparator<WeightedObservedPoint> createWeightedObservedPointComparator() {\nreturn new Comparator<WeightedObservedPoint>() {\nif (p1 == null && p2 == null) {\nif (p1 == null) {\nif (p2 == null) {\nif (p1.getX() < p2.getX()) {\nreturn -1;\n}",
            "method_id": 61
        },
        {
            "method_signature": "org.apache.commons.math.exception.OutOfRangeException:<init>(Ljava/lang/Number;Ljava/lang/Number;Ljava/lang/Number;)V",
            "method_body": "public OutOfRangeException(Number wrong,\nthis(null, wrong, lo, hi);\n}",
            "method_id": 62
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.GaussianFitter$ParameterGuesser:createWeightedObservedPointComparator()Ljava/util/Comparator;",
            "method_body": "private Comparator<WeightedObservedPoint> createWeightedObservedPointComparator() {\nreturn new Comparator<WeightedObservedPoint>() {\nif (p1 == null && p2 == null) {\nif (p1 == null) {\nif (p2 == null) {\nif (p1.getX() < p2.getX()) {\nreturn -1;\n}",
            "method_id": 63
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter:fit(Lorg/apache/commons/math/analysis/ParametricUnivariateRealFunction;[D)[D",
            "method_body": "public double[] fit(final ParametricUnivariateRealFunction f, final double[] initialGuess) {\nreturn fit(Integer.MAX_VALUE, f, initialGuess);\n}",
            "method_id": 64
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter:addObservedPoint(DDD)V",
            "method_body": "public void addObservedPoint(double weight, double x, double y) {\nobservations.add(new WeightedObservedPoint(weight, x, y));\n}",
            "method_id": 65
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:qrDecomposition()V",
            "method_body": "private void qrDecomposition() throws ConvergenceException {\nfor (int k = 0; k < cols; ++k) {\npermutation[k] = k;\ndouble norm2 = 0;\nfor (int i = 0; i < weightedResidualJacobian.length; ++i) {\ndouble akk = weightedResidualJacobian[i][k];\nnorm2 += akk * akk;\njacNorm[k] = FastMath.sqrt(norm2);\nfor (int k = 0; k < cols; ++k) {\nint nextColumn = -1;\ndouble ak2 = Double.NEGATIVE_INFINITY;\nfor (int i = k; i < cols; ++i) {\ndouble norm2 = 0;\nfor (int j = k; j < weightedResidualJacobian.length; ++j) {\ndouble aki = weightedResidualJacobian[j][permutation[i]];\nnorm2 += aki * aki;\nif (Double.isInfinite(norm2) || Double.isNaN(norm2)) {\nif (norm2 > ak2) {\nnextColumn = i;\nak2        = norm2;\nif (ak2 <= qrRankingThreshold) {\nint pk                  = permutation[nextColumn];\npermutation[nextColumn] = permutation[k];\npermutation[k]          = pk;\ndouble akk   = weightedResidualJacobian[k][pk];\ndouble alpha = (akk > 0) ? -FastMath.sqrt(ak2) : FastMath.sqrt(ak2);\ndouble betak = 1.0 / (ak2 - akk * alpha);\nbeta[pk]     = betak;\ndiagR[pk]        = alpha;\nweightedResidualJacobian[k][pk] -= alpha;\nfor (int dk = cols - 1 - k; dk > 0; --dk) {\ndouble gamma = 0;\nfor (int j = k; j < weightedResidualJacobian.length; ++j) {\ngamma += weightedResidualJacobian[j][pk] * weightedResidualJacobian[j][permutation[k + dk]];\ngamma *= betak;\nfor (int j = k; j < weightedResidualJacobian.length; ++j) {\nweightedResidualJacobian[j][permutation[k + dk]] -= gamma * weightedResidualJacobian[j][pk];\nrank = solvedCols;\n}",
            "method_id": 66
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter$TheoreticalValuesFunction:value([D)[D",
            "method_body": "public double[] value(double[] point) {\nfinal double[] values = new double[observations.size()];\nint i = 0;\nfor (WeightedObservedPoint observed : observations) {\nvalues[i++] = f.value(observed.getX(), point);\nreturn values;\n}",
            "method_id": 67
        },
        {
            "method_signature": "org.apache.commons.math.util.Incrementor:incrementCount()V",
            "method_body": "public void incrementCount() {\nif (++count > maximalCount) {\n}",
            "method_id": 68
        },
        {
            "method_signature": "org.apache.commons.math.optimization.direct.BaseAbstractVectorialOptimizer:computeObjectiveValue([D)[D",
            "method_body": "protected double[] computeObjectiveValue(double[] point) {\nevaluations.incrementCount();\n}\nreturn function.value(point);\n}",
            "method_id": 69
        }
    ]
}