{
    "bug_id": 58,
    "test_id": 0,
    "test_name": "org.apache.commons.math.optimization.fitting.GaussianFitterTest.testMath519",
    "test_body": "public void testMath519() {\n// The optimizer will try negative sigma values but \"GaussianFitter\"\n// will catch the raised exceptions and return NaN values instead.\n302: final double[] data = { \n1.1143831578403364E-29,\n4.95281403484594E-28,\n1.1171347211930288E-26,\n1.7044813962636277E-25,\n1.9784716574832164E-24,\n1.8630236407866774E-23,\n1.4820532905097742E-22,\n1.0241963854632831E-21,\n6.275077366673128E-21,\n3.461808994532493E-20,\n1.7407124684715706E-19,\n8.056687953553974E-19,\n3.460193945992071E-18,\n1.3883326374011525E-17,\n5.233894983671116E-17,\n1.8630791465263745E-16,\n6.288759227922111E-16,\n2.0204433920597856E-15,\n6.198768938576155E-15,\n1.821419346860626E-14,\n5.139176445538471E-14,\n1.3956427429045787E-13,\n3.655705706448139E-13,\n9.253753324779779E-13,\n2.267636001476696E-12,\n5.3880460095836855E-12,\n1.2431632654852931E-11\n};\n332: GaussianFitter fitter = new GaussianFitter(new LevenbergMarquardtOptimizer());\nfor (int i = 0; i < data.length; i++) {\nfitter.addObservedPoint(i, data[i]);\n}\nfinal double[] p = fitter.fit();\n338: Assert.assertEquals(53.1572792, p[1], 1e-7);\nAssert.assertEquals(5.75214622, p[2], 1e-8);\n}\n",
    "stack_trace": "org.apache.commons.math.exception.NotStrictlyPositiveException: -1.277 is smaller than, or equal to, the minimum (0)\nat org.apache.commons.math.analysis.function.Gaussian$Parametric.validateParameters(Gaussian.java:183)\nat org.apache.commons.math.analysis.function.Gaussian$Parametric.value(Gaussian.java:128)\nat org.apache.commons.math.optimization.fitting.CurveFitter$TheoreticalValuesFunction.value(CurveFitter.java:203)\nat org.apache.commons.math.optimization.direct.BaseAbstractVectorialOptimizer.computeObjectiveValue(BaseAbstractVectorialOptimizer.java:107)\nat org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer.updateResidualsAndCost(AbstractLeastSquaresOptimizer.java:128)\nat org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer.doOptimize(LevenbergMarquardtOptimizer.java:350)\nat org.apache.commons.math.optimization.direct.BaseAbstractVectorialOptimizer.optimize(BaseAbstractVectorialOptimizer.java:141)\nat org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer.optimize(AbstractLeastSquaresOptimizer.java:253)\nat org.apache.commons.math.optimization.general.AbstractLeastSquaresOptimizer.optimize(AbstractLeastSquaresOptimizer.java:43)\nat org.apache.commons.math.optimization.fitting.CurveFitter.fit(CurveFitter.java:160)\nat org.apache.commons.math.optimization.fitting.CurveFitter.fit(CurveFitter.java:126)\nat org.apache.commons.math.optimization.fitting.GaussianFitter.fit(GaussianFitter.java:121)\nat org.apache.commons.math.optimization.fitting.GaussianFitterTest.testMath519(GaussianFitterTest.java:336)",
    "covered_methods": [
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.WeightedObservedPoint:getWeight()D",
            "method_body": "public double getWeight() {\nreturn weight;\n}",
            "method_id": 20
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.WeightedObservedPoint:getX()D",
            "method_body": "public double getX() {\nreturn x;\n}",
            "method_id": 21
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.WeightedObservedPoint:getY()D",
            "method_body": "public double getY() {\nreturn y;\n}",
            "method_id": 22
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter$TheoreticalValuesFunction:<init>(Lorg/apache/commons/math/optimization/fitting/CurveFitter;Lorg/apache/commons/math/analysis/ParametricUnivariateRealFunction;)V",
            "method_body": "public TheoreticalValuesFunction(final ParametricUnivariateRealFunction f) {\nthis.f = f;\n}",
            "method_id": 23
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter$TheoreticalValuesFunction:jacobian()Lorg/apache/commons/math/analysis/MultivariateMatrixFunction;",
            "method_body": "public MultivariateMatrixFunction jacobian() {\nreturn new MultivariateMatrixFunction() {\nfinal double[][] jacobian = new double[observations.size()][];\nint i = 0;\nfor (WeightedObservedPoint observed : observations) {\njacobian[i++] = f.gradient(observed.getX(), point);\nreturn jacobian;\n}",
            "method_id": 24
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter$TheoreticalValuesFunction:value([D)[D",
            "method_body": "public double[] value(double[] point) {\nfinal double[] values = new double[observations.size()];\nint i = 0;\nfor (WeightedObservedPoint observed : observations) {\nvalues[i++] = f.value(observed.getX(), point);\nreturn values;\n}",
            "method_id": 25
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter$TheoreticalValuesFunction$1:value([D)[[D",
            "method_body": "public MultivariateMatrixFunction jacobian() {\nreturn new MultivariateMatrixFunction() {\nfinal double[][] jacobian = new double[observations.size()][];\nint i = 0;\nfor (WeightedObservedPoint observed : observations) {\njacobian[i++] = f.gradient(observed.getX(), point);\nreturn jacobian;\n}",
            "method_id": 26
        },
        {
            "method_signature": "org.apache.commons.math.exception.OutOfRangeException:<init>(Ljava/lang/Number;Ljava/lang/Number;Ljava/lang/Number;)V",
            "method_body": "public OutOfRangeException(Number wrong,\nthis(null, wrong, lo, hi);\n}",
            "method_id": 27
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter:addObservedPoint(DDD)V",
            "method_body": "public void addObservedPoint(double weight, double x, double y) {\nobservations.add(new WeightedObservedPoint(weight, x, y));\n}",
            "method_id": 28
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.WeightedObservedPoint:<init>(DDD)V",
            "method_body": "public WeightedObservedPoint(final double weight, final double x, final double y) {\nthis.weight = weight;\nthis.x      = x;\nthis.y      = y;\n}",
            "method_id": 29
        },
        {
            "method_signature": "org.apache.commons.math.optimization.fitting.CurveFitter:<init>(Lorg/apache/commons/math/optimization/DifferentiableMultivariateVectorialOptimizer;)V",
            "method_body": "public CurveFitter(final DifferentiableMultivariateVectorialOptimizer optimizer) {\nthis.optimizer = optimizer;\nobservations = new ArrayList<WeightedObservedPoint>();\n}",
            "method_id": 30
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:determineLMDirection([D[D[D[D)V",
            "method_body": "private void determineLMDirection(double[] qy, double[] diag,\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nfor (int i = j + 1; i < solvedCols; ++i) {\nweightedResidualJacobian[i][pj] = weightedResidualJacobian[j][permutation[i]];\nlmDir[j] = diagR[pj];\nwork[j]  = qy[j];\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble dpj = diag[pj];\nif (dpj != 0) {\nArrays.fill(lmDiag, j + 1, lmDiag.length, 0);\nlmDiag[j] = dpj;\ndouble qtbpj = 0;\nfor (int k = j; k < solvedCols; ++k) {\nint pk = permutation[k];\nif (lmDiag[k] != 0) {\ndouble rkk = weightedResidualJacobian[k][pk];\nif (FastMath.abs(rkk) < FastMath.abs(lmDiag[k])) {\nfinal double cotan = rkk / lmDiag[k];\nsin   = 1.0 / FastMath.sqrt(1.0 + cotan * cotan);\ncos   = sin * cotan;\n} else {\nfinal double tan = lmDiag[k] / rkk;\ncos = 1.0 / FastMath.sqrt(1.0 + tan * tan);\nsin = cos * tan;\nweightedResidualJacobian[k][pk] = cos * rkk + sin * lmDiag[k];\nfinal double temp = cos * work[k] + sin * qtbpj;\nqtbpj = -sin * work[k] + cos * qtbpj;\nwork[k] = temp;\nfor (int i = k + 1; i < solvedCols; ++i) {\ndouble rik = weightedResidualJacobian[i][pk];\nfinal double temp2 = cos * rik + sin * lmDiag[i];\nlmDiag[i] = -sin * rik + cos * lmDiag[i];\nweightedResidualJacobian[i][pk] = temp2;\nlmDiag[j] = weightedResidualJacobian[j][permutation[j]];\nweightedResidualJacobian[j][permutation[j]] = lmDir[j];\nint nSing = solvedCols;\nfor (int j = 0; j < solvedCols; ++j) {\nif ((lmDiag[j] == 0) && (nSing == solvedCols)) {\nif (nSing < solvedCols) {\nif (nSing > 0) {\nfor (int j = nSing - 1; j >= 0; --j) {\nint pj = permutation[j];\ndouble sum = 0;\nfor (int i = j + 1; i < nSing; ++i) {\nsum += weightedResidualJacobian[i][pj] * work[i];\nwork[j] = (work[j] - sum) / lmDiag[j];\nfor (int j = 0; j < lmDir.length; ++j) {\nlmDir[permutation[j]] = work[j];\n}",
            "method_id": 31
        },
        {
            "method_signature": "org.apache.commons.math.optimization.AbstractConvergenceChecker:getAbsoluteThreshold()D",
            "method_body": "public double getAbsoluteThreshold() {\nreturn absoluteThreshold;\n}",
            "method_id": 32
        },
        {
            "method_signature": "org.apache.commons.math.optimization.AbstractConvergenceChecker:getRelativeThreshold()D",
            "method_body": "public double getRelativeThreshold() {\nreturn relativeThreshold;\n}",
            "method_id": 33
        },
        {
            "method_signature": "org.apache.commons.math.exception.NumberIsTooSmallException:<init>(Ljava/lang/Number;Ljava/lang/Number;Z)V",
            "method_body": "public NumberIsTooSmallException(Number wrong,\nthis(null, wrong, min, boundIsAllowed);\n}",
            "method_id": 34
        },
        {
            "method_signature": "org.apache.commons.math.optimization.AbstractConvergenceChecker:<init>()V",
            "method_body": "public AbstractConvergenceChecker() {\nthis.relativeThreshold = DEFAULT_RELATIVE_THRESHOLD;\nthis.absoluteThreshold = DEFAULT_ABSOLUTE_THRESHOLD;\n}",
            "method_id": 35
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:<init>()V",
            "method_body": "public LevenbergMarquardtOptimizer() {\nthis(100, 1e-10, 1e-10, 1e-10, MathUtils.SAFE_MIN);\n}",
            "method_id": 36
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:determineLMParameter([DD[D[D[D[D)V",
            "method_body": "private void determineLMParameter(double[] qy, double delta, double[] diag,\nfor (int j = 0; j < rank; ++j) {\nlmDir[permutation[j]] = qy[j];\nfor (int j = rank; j < cols; ++j) {\nfor (int k = rank - 1; k >= 0; --k) {\nint pk = permutation[k];\ndouble ypk = lmDir[pk] / diagR[pk];\nfor (int i = 0; i < k; ++i) {\nlmDir[permutation[i]] -= ypk * weightedResidualJacobian[i][pk];\nlmDir[pk] = ypk;\ndouble dxNorm = 0;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble s = diag[pj] * lmDir[pj];\nwork1[pj] = s;\ndxNorm += s * s;\ndxNorm = FastMath.sqrt(dxNorm);\ndouble fp = dxNorm - delta;\nif (fp <= 0.1 * delta) {\nlmPar = 0;\nreturn;\ndouble parl = 0;\nif (rank == solvedCols) {\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nwork1[pj] *= diag[pj] / dxNorm;\nsum2 = 0;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble sum = 0;\nfor (int i = 0; i < j; ++i) {\nsum += weightedResidualJacobian[i][pj] * work1[permutation[i]];\ndouble s = (work1[pj] - sum) / diagR[pj];\nwork1[pj] = s;\nsum2 += s * s;\nparl = fp / (delta * sum2);\nsum2 = 0;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble sum = 0;\nfor (int i = 0; i <= j; ++i) {\nsum += weightedResidualJacobian[i][pj] * qy[i];\nsum /= diag[pj];\nsum2 += sum * sum;\ndouble gNorm = FastMath.sqrt(sum2);\ndouble paru = gNorm / delta;\nif (paru == 0) {\nlmPar = FastMath.min(paru, FastMath.max(lmPar, parl));\nif (lmPar == 0) {\nfor (int countdown = 10; countdown >= 0; --countdown) {\nif (lmPar == 0) {\ndouble sPar = FastMath.sqrt(lmPar);\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nwork1[pj] = sPar * diag[pj];\ndetermineLMDirection(qy, work1, work2, work3);\ndxNorm = 0;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble s = diag[pj] * lmDir[pj];\nwork3[pj] = s;\ndxNorm += s * s;\ndxNorm = FastMath.sqrt(dxNorm);\ndouble previousFP = fp;\nfp = dxNorm - delta;\nif ((FastMath.abs(fp) <= 0.1 * delta) ||\nreturn;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nwork1[pj] = work3[pj] * diag[pj] / dxNorm;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nwork1[pj] /= work2[j];\ndouble tmp = work1[pj];\nfor (int i = j + 1; i < solvedCols; ++i) {\nwork1[permutation[i]] -= weightedResidualJacobian[i][pj] * tmp;\nsum2 = 0;\nfor (int j = 0; j < solvedCols; ++j) {\ndouble s = work1[permutation[j]];\nsum2 += s * s;\ndouble correction = fp / (delta * sum2);\nif (fp > 0) {\nparl = FastMath.max(parl, lmPar);\n} else if (fp < 0) {\nparu = FastMath.min(paru, lmPar);\nlmPar = FastMath.max(parl, lmPar + correction);\n}",
            "method_id": 37
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:qTy([D)V",
            "method_body": "private void qTy(double[] y) {\nfor (int k = 0; k < cols; ++k) {\nint pk = permutation[k];\ndouble gamma = 0;\nfor (int i = k; i < rows; ++i) {\ngamma += weightedResidualJacobian[i][pk] * y[i];\ngamma *= beta[pk];\nfor (int i = k; i < rows; ++i) {\ny[i] -= gamma * weightedResidualJacobian[i][pk];\n}",
            "method_id": 38
        },
        {
            "method_signature": "org.apache.commons.math.optimization.general.LevenbergMarquardtOptimizer:doOptimize()Lorg/apache/commons/math/optimization/VectorialPointValuePair;",
            "method_body": "protected VectorialPointValuePair doOptimize() throws MathUserException {\nsolvedCols  = FastMath.min(rows, cols);\ndiagR       = new double[cols];\njacNorm     = new double[cols];\nbeta        = new double[cols];\npermutation = new int[cols];\nlmDir       = new double[cols];\ndouble   delta   = 0;\ndouble   xNorm   = 0;\ndouble[] diag    = new double[cols];\ndouble[] oldX    = new double[cols];\ndouble[] oldRes  = new double[rows];\ndouble[] oldObj  = new double[rows];\ndouble[] qtf     = new double[rows];\ndouble[] work1   = new double[cols];\ndouble[] work2   = new double[cols];\ndouble[] work3   = new double[cols];\nupdateResidualsAndCost();\nlmPar = 0;\nboolean firstIteration = true;\nVectorialPointValuePair current = new VectorialPointValuePair(point, objective);\nint iter = 0;\nfinal ConvergenceChecker<VectorialPointValuePair> checker = getConvergenceChecker();\n++iter;\nfor (int i=0;i<rows;i++) {\nqtf[i]=weightedResiduals[i];\nVectorialPointValuePair previous = current;\nupdateJacobian();\nqrDecomposition();\nqTy(qtf);\nfor (int k = 0; k < solvedCols; ++k) {\nint pk = permutation[k];\nweightedResidualJacobian[k][pk] = diagR[pk];\nif (firstIteration) {\nxNorm = 0;\nfor (int k = 0; k < cols; ++k) {\ndouble dk = jacNorm[k];\nif (dk == 0) {\ndouble xk = dk * point[k];\nxNorm  += xk * xk;\ndiag[k] = dk;\nxNorm = FastMath.sqrt(xNorm);\ndelta = (xNorm == 0) ? initialStepBoundFactor : (initialStepBoundFactor * xNorm);\ndouble maxCosine = 0;\nif (cost != 0) {\nfor (int j = 0; j < solvedCols; ++j) {\nint    pj = permutation[j];\ndouble s  = jacNorm[pj];\nif (s != 0) {\ndouble sum = 0;\nfor (int i = 0; i <= j; ++i) {\nsum += weightedResidualJacobian[i][pj] * qtf[i];\nmaxCosine = FastMath.max(maxCosine, FastMath.abs(sum) / (s * cost));\nif (maxCosine <= orthoTolerance) {\nfor (int j = 0; j < cols; ++j) {\ndiag[j] = FastMath.max(diag[j], jacNorm[j]);\nfor (double ratio = 0; ratio < 1.0e-4;) {\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\noldX[pj] = point[pj];\ndouble previousCost = cost;\ndouble[] tmpVec = weightedResiduals;\nweightedResiduals = oldRes;\noldRes    = tmpVec;\ntmpVec    = objective;\nobjective = oldObj;\noldObj    = tmpVec;\ndetermineLMParameter(qtf, delta, diag, work1, work2, work3);\ndouble lmNorm = 0;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\nlmDir[pj] = -lmDir[pj];\npoint[pj] = oldX[pj] + lmDir[pj];\ndouble s = diag[pj] * lmDir[pj];\nlmNorm  += s * s;\nlmNorm = FastMath.sqrt(lmNorm);\nif (firstIteration) {\ndelta = FastMath.min(delta, lmNorm);\nupdateResidualsAndCost();\ndouble actRed = -1.0;\nif (0.1 * cost < previousCost) {\ndouble r = cost / previousCost;\nactRed = 1.0 - r * r;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\ndouble dirJ = lmDir[pj];\nwork1[j] = 0;\nfor (int i = 0; i <= j; ++i) {\nwork1[i] += weightedResidualJacobian[i][pj] * dirJ;\ndouble coeff1 = 0;\nfor (int j = 0; j < solvedCols; ++j) {\ncoeff1 += work1[j] * work1[j];\ndouble pc2 = previousCost * previousCost;\ncoeff1 = coeff1 / pc2;\ndouble coeff2 = lmPar * lmNorm * lmNorm / pc2;\ndouble preRed = coeff1 + 2 * coeff2;\ndouble dirDer = -(coeff1 + coeff2);\nratio = (preRed == 0) ? 0 : (actRed / preRed);\nif (ratio <= 0.25) {\ndouble tmp =\nif ((0.1 * cost >= previousCost) || (tmp < 0.1)) {\ndelta = tmp * FastMath.min(delta, 10.0 * lmNorm);\nlmPar /= tmp;\n} else if ((lmPar == 0) || (ratio >= 0.75)) {\ndelta = 2 * lmNorm;\nlmPar *= 0.5;\nif (ratio >= 1.0e-4) {\nfirstIteration = false;\nxNorm = 0;\nfor (int k = 0; k < cols; ++k) {\ndouble xK = diag[k] * point[k];\nxNorm += xK * xK;\nxNorm = FastMath.sqrt(xNorm);\ncurrent = new VectorialPointValuePair(point, objective);\nif (checker != null) {\nif (checker.converged(iter, previous, current)) {\ncost = previousCost;\nfor (int j = 0; j < solvedCols; ++j) {\nint pj = permutation[j];\npoint[pj] = oldX[pj];\ntmpVec    = weightedResiduals;\nweightedResiduals = oldRes;\noldRes    = tmpVec;\ntmpVec    = objective;\nobjective = oldObj;\noldObj    = tmpVec;\nif ((FastMath.abs(actRed) <= costRelativeTolerance &&\nif ((FastMath.abs(actRed) <= 2.2204e-16) && (preRed <= 2.2204e-16) && (ratio <= 2.0)) {\n} else if (delta <= 2.2204e-16 * xNorm) {\n} else if (maxCosine <= 2.2204e-16)  {\n}\n}\n}",
            "method_id": 39
        }
    ]
}