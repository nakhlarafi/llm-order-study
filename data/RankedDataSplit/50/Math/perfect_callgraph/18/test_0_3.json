{
    "bug_id": 18,
    "test_id": 0,
    "test_name": "org.apache.commons.math3.optimization.direct.CMAESOptimizerTest.testFitAccuracyDependsOnBoundary",
    "test_body": "public void testFitAccuracyDependsOnBoundary() {\nfinal CMAESOptimizer optimizer = new CMAESOptimizer();\nfinal MultivariateFunction fitnessFunction = new MultivariateFunction() {\npublic double value(double[] parameters) {\nfinal double target = 11.1;\nfinal double error = target - parameters[0];\nreturn error * error;\n}\n};\n449: final double[] start = { 1 };\n451: // No bounds.\nPointValuePair result = optimizer.optimize(100000, fitnessFunction, GoalType.MINIMIZE,\nstart);\nfinal double resNoBound = result.getPoint()[0];\n456: // Optimum is near the lower bound.\nfinal double[] lower = { -20 };\nfinal double[] upper = { 5e16 };\nresult = optimizer.optimize(100000, fitnessFunction, GoalType.MINIMIZE,\nstart, lower, upper);\nfinal double resNearLo = result.getPoint()[0];\n463: // Optimum is near the upper bound.\nlower[0] = -5e16;\nupper[0] = 20;\nresult = optimizer.optimize(100000, fitnessFunction, GoalType.MINIMIZE,\nstart, lower, upper);\nfinal double resNearHi = result.getPoint()[0];\n470: // System.out.println(\"resNoBound=\" + resNoBound +\n//                    \" resNearLo=\" + resNearLo +\n//                    \" resNearHi=\" + resNearHi);\n474: // The two values currently differ by a substantial amount, indicating that\n// the bounds definition can prevent reaching the optimum.\nAssert.assertEquals(resNoBound, resNearLo, 1e-3);\nAssert.assertEquals(resNoBound, resNearHi, 1e-3);\n}\n",
    "stack_trace": "junit.framework.AssertionFailedError: expected:<11.100000000388787> but was:<8.0>\nat org.junit.Assert.fail(Assert.java:88)\nat org.junit.Assert.failNotEquals(Assert.java:743)\nat org.junit.Assert.assertEquals(Assert.java:494)\nat org.junit.Assert.assertEquals(Assert.java:592)\nat org.apache.commons.math3.optimization.direct.CMAESOptimizerTest.testFitAccuracyDependsOnBoundary(CMAESOptimizerTest.java:477)",
    "covered_methods": [
        {
            "method_signature": "org.apache.commons.math3.linear.Array2DRowRealMatrix:createMatrix(II)Lorg/apache/commons/math3/linear/RealMatrix;",
            "method_body": "public RealMatrix createMatrix(final int rowDimension,\nreturn new Array2DRowRealMatrix(rowDimension, columnDimension);\n}",
            "method_id": 150
        },
        {
            "method_signature": "org.apache.commons.math3.linear.TriDiagonalTransformer:<init>(Lorg/apache/commons/math3/linear/RealMatrix;)V",
            "method_body": "public TriDiagonalTransformer(RealMatrix matrix) {\nif (!matrix.isSquare()) {\nfinal int m = matrix.getRowDimension();\nhouseholderVectors = matrix.getData();\nmain      = new double[m];\nsecondary = new double[m - 1];\ncachedQ   = null;\ncachedQt  = null;\ncachedT   = null;\ntransform();\n}",
            "method_id": 151
        },
        {
            "method_signature": "org.apache.commons.math3.optimization.direct.CMAESOptimizer:doOptimize()Lorg/apache/commons/math3/optimization/PointValuePair;",
            "method_body": "protected PointValuePair doOptimize() {\ncheckParameters();\nisMinimize = getGoalType().equals(GoalType.MINIMIZE);\nfinal FitnessFunction fitfun = new FitnessFunction();\nfinal double[] guess = fitfun.encode(getStartPoint());\ndimension = guess.length;\ninitializeCMA(guess);\niterations = 0;\ndouble bestValue = fitfun.value(guess);\npush(fitnessHistory, bestValue);\nPointValuePair optimum = new PointValuePair(getStartPoint(),\nPointValuePair lastResult = null;\nfor (iterations = 1; iterations <= maxIterations; iterations++) {\nRealMatrix arz = randn1(dimension, lambda);\nRealMatrix arx = zeros(dimension, lambda);\ndouble[] fitness = new double[lambda];\nfor (int k = 0; k < lambda; k++) {\nRealMatrix arxk = null;\nfor (int i = 0; i < checkFeasableCount+1; i++) {\nif (diagonalOnly <= 0) {\narxk = xmean.add(BD.multiply(arz.getColumnMatrix(k))\nif (i >= checkFeasableCount || fitfun.isFeasible(arxk.getColumn(0))) {\ncopyColumn(arxk, 0, arx, k);\nfitness[k] = fitfun.value(arx.getColumn(k)); // compute fitness\n}\nint[] arindex = sortedIndices(fitness);\nRealMatrix xold = xmean; // for speed up of Eq. (2) and (3)\nRealMatrix bestArx = selectColumns(arx, MathArrays.copyOf(arindex, mu));\nxmean = bestArx.multiply(weights);\nRealMatrix bestArz = selectColumns(arz, MathArrays.copyOf(arindex, mu));\nRealMatrix zmean = bestArz.multiply(weights);\nboolean hsig = updateEvolutionPaths(zmean, xold);\nif (diagonalOnly <= 0) {\nupdateCovariance(hsig, bestArx, arz, arindex, xold);\nsigma *= Math.exp(Math.min(1.0,(normps/chiN - 1.)*cs/damps));\ndouble bestFitness = fitness[arindex[0]];\ndouble worstFitness = fitness[arindex[arindex.length-1]];\nif (bestValue > bestFitness) {\nbestValue = bestFitness;\nlastResult = optimum;\noptimum = new PointValuePair(\nif (getConvergenceChecker() != null && lastResult != null) {\nif (getConvergenceChecker().converged(iterations, optimum, lastResult)) {\nif (stopFitness != 0) { // only if stopFitness is defined\ndouble[] sqrtDiagC = sqrt(diagC).getColumn(0);\ndouble[] pcCol = pc.getColumn(0);\nfor (int i = 0; i < dimension; i++) {\nif (sigma*(Math.max(Math.abs(pcCol[i]), sqrtDiagC[i])) > stopTolX) {\nbreak;\nfor (int i = 0; i < dimension; i++) {\nif (sigma*sqrtDiagC[i] > stopTolUpX) {\ndouble historyBest = min(fitnessHistory);\ndouble historyWorst = max(fitnessHistory);\nif (iterations > 2 && Math.max(historyWorst, worstFitness) -\nbreak generationLoop;\nif (iterations > fitnessHistory.length &&\nif (max(diagD)/min(diagD) > 1e7) {\nif (getConvergenceChecker() != null) {\nPointValuePair current =\nif (lastResult != null &&\nbreak generationLoop;\nlastResult = current;\nif (bestValue == fitness[arindex[(int)(0.1+lambda/4.)]]) {\nsigma = sigma * Math.exp(0.2+cs/damps);\nif (iterations > 2 && Math.max(historyWorst, bestFitness) -\npush(fitnessHistory,bestFitness);\nfitfun.setValueRange(worstFitness-bestFitness);\nif (generateStatistics) {\nreturn optimum;\n}",
            "method_id": 152
        },
        {
            "method_signature": "org.apache.commons.math3.linear.MatrixUtils:checkColumnIndex(Lorg/apache/commons/math3/linear/AnyMatrix;I)V",
            "method_body": "public static void checkColumnIndex(final AnyMatrix m, final int column)\nif (column < 0 || column >= m.getColumnDimension()) {\n}",
            "method_id": 153
        },
        {
            "method_signature": "org.apache.commons.math3.optimization.direct.CMAESOptimizer$FitnessFunction:setValueRange(D)V",
            "method_body": "public void setValueRange(double valueRange) {\nthis.valueRange = valueRange;\n}",
            "method_id": 154
        },
        {
            "method_signature": "org.apache.commons.math3.optimization.direct.CMAESOptimizer:updateCovariance(ZLorg/apache/commons/math3/linear/RealMatrix;Lorg/apache/commons/math3/linear/RealMatrix;[ILorg/apache/commons/math3/linear/RealMatrix;)V",
            "method_body": "private void updateCovariance(boolean hsig, final RealMatrix bestArx,\ndouble negccov = 0;\nif (ccov1 + ccovmu > 0) {\nRealMatrix arpos = bestArx.subtract(repmat(xold, 1, mu))\nRealMatrix roneu = pc.multiply(pc.transpose())\ndouble oldFac = hsig ? 0 : ccov1 * cc * (2. - cc);\noldFac += 1. - ccov1 - ccovmu;\nif (isActiveCMA) {\nnegccov = (1. - ccovmu) * 0.25 * mueff /\ndouble negminresidualvariance = 0.66;\ndouble negalphaold = 0.5; // where to make up for the variance\nint[] arReverseIndex = reverse(arindex);\nRealMatrix arzneg\nRealMatrix arnorms = sqrt(sumRows(square(arzneg)));\nint[] idxnorms = sortedIndices(arnorms.getRow(0));\nRealMatrix arnormsSorted = selectColumns(arnorms, idxnorms);\nint[] idxReverse = reverse(idxnorms);\nRealMatrix arnormsReverse = selectColumns(arnorms, idxReverse);\narnorms = divide(arnormsReverse, arnormsSorted);\nint[] idxInv = inverse(idxnorms);\nRealMatrix arnormsInv = selectColumns(arnorms, idxInv);\ndouble negcovMax = (1. - negminresidualvariance) /\nif (negccov > negcovMax) {\nnegccov = negcovMax;\narzneg = times(arzneg, repmat(arnormsInv, dimension, 1));\nRealMatrix artmp = BD.multiply(arzneg);\nRealMatrix Cneg = artmp.multiply(diag(weights)).multiply(\noldFac += negalphaold * negccov;\nC = C.scalarMultiply(oldFac)\n} else {\nupdateBD(negccov);\n}",
            "method_id": 155
        },
        {
            "method_signature": "org.apache.commons.math3.linear.Array2DRowRealMatrix:copyIn([[D)V",
            "method_body": "private void copyIn(final double[][] in)\nsetSubMatrix(in, 0, 0);\n}",
            "method_id": 156
        },
        {
            "method_signature": "org.apache.commons.math3.linear.MatrixUtils:checkRowIndex(Lorg/apache/commons/math3/linear/AnyMatrix;I)V",
            "method_body": "public static void checkRowIndex(final AnyMatrix m, final int row)\nif (row < 0 ||\n}",
            "method_id": 157
        }
    ]
}